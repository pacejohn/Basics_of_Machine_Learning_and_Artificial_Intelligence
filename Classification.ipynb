{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Classification_01.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns \n",
    "import sklearn\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import statsmodels.api as sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data for houses in Memphis in the 38118 zip code and Amarillow in the 79106 area for Logistic Regression\n",
    "cols=[\"SF\",\"Price\",\"Beds\",\"Baths\",\"Year_Built\",\"Lot_Size_Acres\",\"Garage_Size\",\"Stories\",\"Brick\",\"City\"]\n",
    "City_Log_Reg_df = pd.read_csv('data/Logistic_Regression_Memphis_vs_Amarillo.csv', names=cols)\n",
    "\n",
    "# See the first few lines of data\n",
    "print(\"Overview of data:\")\n",
    "print(City_Log_Reg_df.head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a model to classify the house is in Memphis (38118) or Amarillo (79106)\n",
    "* We will do this using Logistic Regression and the model will use all of the attributes from the Multiple Variable Linear Regression section above.\n",
    "* We will divide our data up into 2 groups - the training group and testing group.  80% will be in training, 20% in testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a NumPy array, and split it into a training and test set\n",
    "X_train = City_Log_Reg_df.drop(\"City\", axis=1).values\n",
    "y_train = City_Log_Reg_df[\"City\"].values\n",
    "\n",
    "# Create train/test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# Train the model\n",
    "LogReg = LogisticRegression(penalty = 'l2')\n",
    "LogReg.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions based on the model we just created and see how well it performs.\n",
    "* The 2 classes are 0 and 1.  0 means the house is in Memphis, 1 means the house is in Amarillo.\n",
    "* A confusion matrix will show how each house was classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = LogReg.predict(X_test)\n",
    "#print(y_pred)\n",
    "y_pred_probs = LogReg.predict_proba(X_test)\n",
    "#print(y_pred_probs)\n",
    "\n",
    "# Generate the confusion matrix data\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Prepare the plot\n",
    "class_names=[\"0\",\"1\"]\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(confusion_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion Matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Print additional info for the confusion matrix\n",
    "print(\"\\n\" + str(confusion_matrix[0][0]) + \" houses that are in Memphis (class 0) were classified as in Memphis.\")\n",
    "print(str(confusion_matrix[0][1]) + \" houses that are in M were classified as in Amarillo.\")\n",
    "print(str(confusion_matrix[1][0]) + \" houses that are in Amarillo (class 1) were classified as in Memphis.\")\n",
    "print(str(confusion_matrix[1][1]) + \" houses that are in Amarillo were classified as in Amarillo.\\n\")\n",
    "\n",
    "print(\"The accuracy of the logistic regression classifier on the test set is {:.2f}.\\n\".format(LogReg.score(X_test, y_test)))\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the AUC\n",
    "The Area Under the Receiver Operating Curve is a numerical value that tells how well a model can distinguish between the different classes. The higher the AUC, which ranges from 0 to 1, better the model.  An AUC of 0.5 indicates the model is randomly guessing.  It represents the False Positive Rate vs the True Positive Rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the AUC and draw the ROC curve\n",
    "\n",
    "# Get the predicted probabilities and other data needed for AUC\n",
    "y_pred_auc = LogReg.predict_proba(X_test)[::,1]\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_auc)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_auc)\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=fpr, y=tpr))\n",
    "fig.update_layout(title=\"AUC - {:.3f}\".format(auc),\n",
    "                   xaxis_title=\"False Positive Rate\",\n",
    "                   yaxis_title=\"True Positive Rate\")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nThe AUC is {:.3f}.\".format(auc))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the actual classifications.  These show which city the house was really in (\"City\") and the probability that it was in Memphis or Amarillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in range(len(y_test)):\n",
    "    if (int(y_test[i]) == 0):\n",
    "        city = \"Memphis\"\n",
    "    else:\n",
    "        city = \"Amarillo\"\n",
    "\n",
    "    outcome = \"\"\n",
    "\n",
    "    if(y_pred[i] == y_test[i]):\n",
    "        outcome = \" - CORRECT\"\n",
    "        counter += 1\n",
    "        \n",
    "    print(\"SF = {:,d}, Price = {:,d}, City = {}, Prob of Memphis = {:.3f}, Prob of Amarillo = {:.3f}{}\".format(int(X_test[i][0]),\n",
    "                                                                                                      int(X_test[i][1]),\n",
    "                                                                                                      city,\n",
    "                                                                                                      y_pred_probs[i][0],\n",
    "                                                                                                      y_pred_probs[i][1],\n",
    "                                                                                                      outcome))\n",
    "    \n",
    "print(\"\\nAccuracy of classifications is {:.2f}.\".format(counter / (len(y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Could cross validation help?\n",
    "\n",
    "![title](./images/Cross_Validation_01.JPG)\n",
    "Image from https://en.wikipedia.org/wiki/Cross-validation_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with Memphis vs. Newport Beach, CA - an incredibly expensive city!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data for houses in Memphis in the 38118 zip code for Simple Linear Regression\n",
    "cols=[\"SF\",\"Price\",\"Beds\",\"Baths\",\"Year_Built\",\"Lot_Size_Acres\",\"Garage_Size\",\"Stories\",\"Brick\",\"City\"]\n",
    "City_Log_Reg_df = pd.read_csv('data/Logistic_Regression_Memphis_vs_Newport_Beach.csv', names=cols)\n",
    "\n",
    "# Create scatterplot\n",
    "fig = px.scatter(City_Log_Reg_df, x=\"SF\", y=\"Price\", color=City_Log_Reg_df[\"City\"].astype(str))\n",
    "fig.update_xaxes(title_text='SF')\n",
    "fig.update_yaxes(title_text='Price ($)')\n",
    "fig.update_layout(title_text='House prices as a function of square footage in Memphis and Newport Beach', title_x=0.5)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the first few lines of data\n",
    "print(\"Overview of data:\")\n",
    "print(City_Log_Reg_df.head(3))\n",
    "\n",
    "# Convert the dataframe to a NumPy array, and split it into a training and test set\n",
    "X_train = City_Log_Reg_df.drop(\"City\", axis=1).values\n",
    "y_train = City_Log_Reg_df[\"City\"].values\n",
    "\n",
    "# Create train/test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# Train the model\n",
    "LogReg = LogisticRegression(penalty = 'l2')\n",
    "LogReg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = LogReg.predict(X_test)\n",
    "#print(y_pred)\n",
    "y_pred_probs = LogReg.predict_proba(X_test)\n",
    "#print(y_pred_probs)\n",
    "\n",
    "# Generate the confustion matrix data\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Prepare the plot\n",
    "class_names=[\"0\",\"1\"] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(confusion_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion Matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Print additional info for the confusion matrix\n",
    "print(\"\\n\" + str(confusion_matrix[0][0]) + \" houses that are in Memphis (class 0) were classified as in Memphis.\")\n",
    "print(str(confusion_matrix[0][1]) + \" houses that are in Memphis were classified as in Newport Beach.\")\n",
    "print(str(confusion_matrix[1][0]) + \" houses that are in Newport Beach (class 1) were classified as in Memphis.\")\n",
    "print(str(confusion_matrix[1][1]) + \" houses that are in Newport Beach were classified as in Newport Beach.\\n\")\n",
    "\n",
    "print(\"The accuracy of the logistic regression classifier on the test set is {:.2f}.\\n\".format(LogReg.score(X_test, y_test)))\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate the AUC and draw the ROC curve\n",
    "\n",
    "# Get the predicted probabilities and other data needed for AUC\n",
    "y_pred_auc = LogReg.predict_proba(X_test)[::,1]\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_auc)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_auc)\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=fpr, y=tpr))\n",
    "fig.update_layout(title=\"AUC - {:.3f}\".format(auc),\n",
    "                   xaxis_title=\"False Positive Rate\",\n",
    "                   yaxis_title=\"True Positive Rate\")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nThe AUC is {:.3f}.\".format(auc))\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(y_test)):\n",
    "    if (int(y_test[i]) == 0):\n",
    "        city = \"Memphis\"\n",
    "    else:\n",
    "        city = \"Newport Beach\"\n",
    "\n",
    "    outcome = \"\"\n",
    "    \n",
    "    if ((int(y_test[i]) == 0 and y_pred_probs[i][0] > y_pred_probs[i][1]) or\n",
    "       (int(y_test[i]) == 1 and y_pred_probs[i][0] < y_pred_probs[i][1])):\n",
    "        outcome = \" - CORRECT\"\n",
    "        counter += 1\n",
    "\n",
    "    print(\"SF = {:,d}, Price = {:,d}, City = {}, Prob of Memphis = {:.3f}, Prob of Newport Beach = {:.3f}{}\".format(int(X_test[i][0]),\n",
    "                                                                                                      int(X_test[i][1]),\n",
    "                                                                                                      city,\n",
    "                                                                                                      y_pred_probs[i][0],\n",
    "                                                                                                      y_pred_probs[i][1],\n",
    "                                                                                                      outcome))\n",
    "    \n",
    "print(\"\\nAccuracy of classifications is {:.2f}.\".format(counter / (len(y_test))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using multinomial regression to classify the city a house is located in using the variables from above. The houses can be located in Memphis, Amarillo, or Newport Beach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are using a new dataset.  The dataset has 50 houses for each city.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data for houses in Memphis, Amarillo, and Newport Beach\n",
    "cols=[\"SF\",\"Price\",\"Beds\",\"Baths\",\"Year_Built\",\"Lot_Size_Acres\",\"Garage_Size\",\"Stories\",\"Brick\",\"City\"]\n",
    "Mult_Reg_df = pd.read_csv('data/Multinomial_Regression.csv', names=cols)\n",
    "\n",
    "# See the first few lines of data\n",
    "print(\"Overview of data:\")\n",
    "print(Mult_Reg_df.head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a model to classify where the house is located\n",
    "* We will do this using Multinomial Regression and the model will use all of the attributes from the Logistic Regression section above.\n",
    "* We will divide our data up into 2 groups - the training group and testing group. 80% will be in training, 20% in testing.\n",
    "* There are 50 houses for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a NumPy array, and split it into a training and test set\n",
    "X_train = Mult_Reg_df.drop(\"City\", axis=1).values\n",
    "y_train = Mult_Reg_df[\"City\"].values\n",
    "\n",
    "# Create train/test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# Create the regressor and train the model\n",
    "MultReg = LogisticRegression(random_state=0, multi_class='multinomial', max_iter=7600)\n",
    "MultReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions based on the model we just created and see how well it performs.\n",
    "* The 3 classes are 0, 1, and 2.  0 means the house is in Memphis, 1 means the house is in Amarillo, and 2 means the house is in Newport Beach.\n",
    "* A confusion matrix will show how each house was classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class\n",
    "y_pred = MultReg.predict(X_test)\n",
    "\n",
    "# View predicted probabilities\n",
    "y_pred_probs = MultReg.predict_proba(X_test)\n",
    "#print(y_pred_probs)\n",
    "\n",
    "# Generate the confustion matrix data\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "#print(confusion_matrix)\n",
    "\n",
    "# Prepare the plot\n",
    "class_names=[\"0\",\"1\", \"2\"]\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(confusion_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion Matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "print(\"The accuracy of the multinomial regression classifier on the test set is {:.2f}.\\n\".format(MultReg.score(X_test, y_test)))\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions based on the model we just created and see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in range(len(y_test)):\n",
    "    if (int(y_test[i]) == 0):\n",
    "        city = \"Memphis\"\n",
    "    elif (int(y_test[i]) == 1):\n",
    "        city = \"Amarillo\"\n",
    "    else:\n",
    "        city = \"Newport Beach\"\n",
    "\n",
    "    outcome = \"\"\n",
    "    \n",
    "    if(y_pred[i] == y_test[i]):\n",
    "        outcome = \" - CORRECT\"\n",
    "        counter +=1\n",
    "    \n",
    "    print(\"SF = {:,d}, Price = {:,d}, City = {}, Prob Mem = {:.3f}, Prob Ama = {:.3f}, Prob NB = {:.3f}{}\".format(int(X_test[i][0]), \n",
    "                                                                                                                                               int(X_test[i][1]),\n",
    "                                                                                                                                               city,\n",
    "                                                                                                                                               y_pred_probs[i][0],\n",
    "                                                                                                                                               y_pred_probs[i][1],\n",
    "                                                                                                                                               y_pred_probs[i][2],\n",
    "                                                                                                                                               outcome))\n",
    "    \n",
    "print(\"\\nAccuracy of classifications is {:.2f}.\".format(counter / (len(y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbor classification (KNN)\n",
    "\n",
    "* Supervised method to classify data\n",
    "\n",
    "* The short version is that you place a new data point in space.  Then you find the K closest points, or nearest neighbors.  The new data point is put in the class that the greatest number of neighbors are in.\n",
    "\n",
    "### Details:\n",
    "  \n",
    "* Choose a value of K. Make sure it is an odd number!\n",
    "* Find the distance of the new point to each of the training data points.\n",
    "* Find the K nearest neighbors for the new data point.\n",
    "* Count the number of data points in each category among the K neighbors.  The new data point will belong to the class that has the most neighbors.\n",
    "\n",
    "* Differs from K-means in that you already know which class each data point is in before you place the new data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the value of K\n",
    "![title](./images/KNN_01.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Print the class names \n",
    "print(\"The class names are:\")\n",
    "print(iris.target_names)\n",
    "\n",
    "# Print the feature names\n",
    "print(\"\\nThe feature names are:\")\n",
    "print(iris.feature_names)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Define features and target\n",
    "# X will be all 4 features\n",
    "X = iris.data[:, :4]\n",
    "# y is the type of flower\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model to classify new flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well our classification model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Show the accuracy of the predictions\n",
    "print(\"Test set accuracy: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the new model by making a prediction based on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new sample and use the model built above to predict the species\n",
    "x_new = np.array([[0.1, 8.6, 2.3, 4.1]])\n",
    "\n",
    "# Predict the class for this new sample\n",
    "prediction = knn.predict(x_new)\n",
    "print(\"The predicted class for this sample is \" + str(iris['target_names'][prediction][0]) + \".\")\n",
    "print(\"The correct class is setosa.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But what is the best K?  Let's loop through some values and find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "k_range = range(1,21)\n",
    "\n",
    "# Try values of K from 1 to 20\n",
    "for i in k_range:\n",
    "\n",
    "    # Instantiate the KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "    # Train the model\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    accuracy_list.append(knn.score(X_test, y_test))\n",
    "\n",
    "    # Show the accuracy of the predictions\n",
    "    print(\"Test set accuracy for K={:,d}: {:.2f}\".format(int(i), knn.score(X_test, y_test)))\n",
    "    \n",
    "# Plot the accuracy vs K\n",
    "plt.plot(k_range, accuracy_list)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy for each value of K\")\n",
    "plt.xticks([0,2,4,6,8,10,12,14,16,18,20])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supervised method to classify data\n",
    "* Data is split continuously according to parameters, forming a classification tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree consists of :\n",
    "* Nodes : Test for the value of a certain attribute.\n",
    "* Edges/ Branch : Correspond to the outcome of a test and connect to the next node or leaf.\n",
    "* Leaf nodes : Terminal nodes that predict the outcome (represent class labels or class distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/DT_01.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Print the class names \n",
    "print(\"The class names are:\")\n",
    "print(iris.target_names)\n",
    "\n",
    "# Print the feature names\n",
    "print(\"\\nThe feature names are:\")\n",
    "print(iris.feature_names)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Define features and target\n",
    "# X will be all 4 features\n",
    "X = iris.data[:, :4]\n",
    "# y is the type of flower\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model to classify new flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the actual decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decision tree visual\n",
    "plt.figure(figsize=(25,10))\n",
    "a = plot_tree(dtc, \n",
    "              feature_names=iris.feature_names, \n",
    "              class_names=iris.target_names, \n",
    "              impurity=False,\n",
    "              filled=True, \n",
    "              rounded=True, \n",
    "              fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building a decision tree classifier, you can set many parameters, such as:\n",
    "* max_depth - The maximum depth of the tree\n",
    "* min_samples_split - The minimum number of samples required to split a node.\n",
    "* min_samples_leaf - The minimum number of samples required to be at a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits\n",
    "* https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f\n",
    "* www.plotly.com\n",
    "* https://www.theanalysisfactor.com/assessing-the-fit-of-regression-models/\n",
    "* https://www.statisticshowto.com/rmse/\n",
    "* https://dss.princeton.edu/online_help/analysis/interpreting_regression.htm#coefficients\n",
    "* All the house information came from www.zillow.com\n",
    "* https://towardsdatascience.com/knn-using-scikit-learn-c6bed765be75\n",
    "* https://medium.com/datadriveninvestor/k-nearest-neighbors-knn-7b4bd0128da7\n",
    "* https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn\n",
    "* https://www.kaggle.com/crowemi/iris-classification-k-nearest-neighbors\n",
    "* https://www.datasciencecentral.com/profiles/blogs/classification-and-regression-trees\n",
    "* https://towardsdatascience.com/decision-tree-classification-de64fc4d5aac\n",
    "* https://towardsdatascience.com/how-to-visualize-a-decision-tree-in-5-steps-19781b28ffe2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
